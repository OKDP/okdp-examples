# Default values for okdp-examples.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image:
  repository: quay.io/okdp/okdp-examples
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  tag: "latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

job:
  restartPolicy: Never
  backoffLimit: 2
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": "before-hook-creation"

# -- Extra environment variables in RAW format that will be passed into pods
extraEnvRaw: []
#  - name: MC_INSECURE
#    value: "1"
#  - name: S3_ENDPOINT
#    value: https://minio-default.okdp.sandbox
#  - name: S3_ACCESS_KEY
#    valueFrom:
#      secretKeyRef:
#        name: local-examples-s3
#        key: accessKey
#  - name: S3_SECRET_KEY
#    valueFrom:
#      secretKeyRef:
#        name: local-examples-s3
#        key: secretKey
#  - name: BUCKET
#    value: okdp
#  - name: BUCKET_PREFIX
#    value: "examples/data/raw/tripdata"
#  - name: DATA_URL
#    value: https://d37ci6vzurychx.cloudfront.net/trip-data
#  - name: TRINO_SERVER_URL
#    value: https://trino-default.okdp.sandbox
#  - name: TRINO_TERMINAL
#    value: dumb
#  - name: SPARK_EVENT_LOG_DIRECTORY
#    value: s3a://spark-events/event-logs/

commands:
  01-prepare_env:
    01-create-spark-event-log-dir: |
      echo "ðŸ‘‰ Connect into S3"
      mc alias set myminio $S3_ENDPOINT "$S3_ACCESS_KEY" "$S3_SECRET_KEY"
      echo "ðŸ‘‰ MinIO alias configured successfully."
      echo "ðŸ‘‰ Normalize the log directory $SPARK_EVENT_LOG_DIRECTORY"
      no_scheme="${SPARK_EVENT_LOG_DIRECTORY#s3a://}"
      no_scheme="${no_scheme%/}"
      bucket="${no_scheme%%/*}"
      prefix="${no_scheme#${bucket}}"
      prefix="${prefix#/}"
      echo "ðŸ‘‰ Bucket: $bucket, Prefix: $prefix"
      echo "ðŸ‘‰ Create the bucket $bucket if not exist"
      mc mb myminio/$bucket || true
      echo "ðŸ‘‰ upload a zero-byte object to create the prefix: ${bucket}/${prefix}/.keep"
      mc pipe "myminio/${bucket}/${prefix}/.keep" < /dev/null
      echo "âœ… Spark events log directory $SPARK_EVENT_LOG_DIRECTORY successfully created.";
  02-nyc_trip:
    # https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page
    01-download-nyc-tripdata: |
      mkdir -p /data/tripdata
      cd /data/tripdata;
      for dataset in yellow green fhv; do
        for month in 01 02 03; do
          file="${dataset}_tripdata_2025-${month}.parquet";
          url="$DATA_URL/$file";
          echo "â†’ $url";
          if curl -fsSLO "$url"; then
            echo "âœ… Downloaded: $file";
          else
            echo "âš ï¸ Missing: $file";
          fi;
        done;
      done;
      ls -lh /data/tripdata
      echo "âœ… All downloads complete.";

    02-upload-nyc-tripdata-into-s3: |
      echo "ðŸ‘‰ Connect into S3"
      mc alias set myminio $S3_ENDPOINT "$S3_ACCESS_KEY" "$S3_SECRET_KEY"
      echo "ðŸ‘‰ MinIO alias configured successfully."
      ### echo "ðŸ‘‰ Clean the examples folder if it exists"
      ### mc rm --recursive --force myminio/$BUCKET/examples
      echo "ðŸ‘‰ Create the bucket if not exist"
      mc mb myminio/$BUCKET || true
      echo "ðŸ‘‰ Upload sample files into the correct folders"
      
      for category in yellow green fhv; do
        echo "ðŸš€ Processing category: $category"
        for file in /data/tripdata/${category}_*.parquet; do
          [ -e "$file" ] || continue  # skip if no files match
          month=$(basename "$file" | sed -E 's/.*_([0-9]{4}-[0-9]{2})\.parquet/\1/')
          echo "ðŸ“¦ Uploading $file â†’ ${BUCKET_PREFIX}/$category/month=$month/"
          mc cp "$file" "myminio/$BUCKET/${BUCKET_PREFIX}/$category/month=$month/"
        done
      done
      
      echo "ðŸ‘‰ Verify bucket structure"
      mc tree myminio/$BUCKET
      mc ls --recursive myminio/$BUCKET

    03-nyc-tripdata-trino-external-tables.sql: |
      trino --server ${TRINO_SERVER_URL} --insecure <<SQL
        CREATE SCHEMA IF NOT EXISTS lakehouse.nyc_tripdata;
      
        CREATE TABLE IF NOT EXISTS lakehouse.nyc_tripdata.yellow (
          vendorid INT,
          tpep_pickup_datetime TIMESTAMP,
          tpep_dropoff_datetime TIMESTAMP,
          passenger_count INT,
          trip_distance DOUBLE,
          ratecodeid INT,
          store_and_fwd_flag VARCHAR,
          pulocationid INT,
          dolocationid INT,
          payment_type INT,
          fare_amount DOUBLE,
          extra DOUBLE,
          mta_tax DOUBLE,
          tip_amount DOUBLE,
          tolls_amount DOUBLE,
          improvement_surcharge DOUBLE,
          total_amount DOUBLE,
          congestion_surcharge DOUBLE,
          airport_fee DOUBLE,
          cbd_congestion_fee DOUBLE,
          month VARCHAR
        )
        WITH (
          external_location = 's3a://${BUCKET}/${BUCKET_PREFIX}/yellow/',
          format = 'PARQUET',
          partitioned_by = ARRAY['month']
        );
      
        CREATE TABLE IF NOT EXISTS lakehouse.nyc_tripdata.green (
          vendorid INT,
          lpep_pickup_datetime TIMESTAMP,
          lpep_dropoff_datetime TIMESTAMP,
          store_and_fwd_flag VARCHAR,
          ratecodeid INT,
          pulocationid INT,
          dolocationid INT,
          passenger_count INT,
          trip_distance DOUBLE,
          fare_amount DOUBLE,
          extra DOUBLE,
          mta_tax DOUBLE,
          tip_amount DOUBLE,
          tolls_amount DOUBLE,
          improvement_surcharge DOUBLE,
          total_amount DOUBLE,
          payment_type INT,
          trip_type INT,
          congestion_surcharge DOUBLE,
          cbd_congestion_fee DOUBLE,
          month VARCHAR
        )
        WITH (
          external_location = 's3a://${BUCKET}/${BUCKET_PREFIX}/green/',
          format = 'PARQUET',
          partitioned_by = ARRAY['month']
        );
      
        CREATE TABLE IF NOT EXISTS lakehouse.nyc_tripdata.fhv (
          dispatching_base_num VARCHAR,
          pickup_datetime TIMESTAMP,
          dropoff_datetime TIMESTAMP,
          pulocationid INT,
          dolocationid INT,
          sr_flag INT,
          affiliated_base_number VARCHAR,
          month VARCHAR
        )
        WITH (
          external_location = 's3a://${BUCKET}/${BUCKET_PREFIX}/fhv/',
          format = 'PARQUET',
          partitioned_by = ARRAY['month']
        );
      SQL

    04-nyc-tripdata-trino-synchronize-partitions: |
      trino --server ${TRINO_SERVER_URL} --insecure <<SQL
        CALL lakehouse.system.sync_partition_metadata(
          schema_name => 'nyc_tripdata',
          table_name => 'yellow',
          mode => 'ADD'
        );
        CALL lakehouse.system.sync_partition_metadata(
          schema_name => 'nyc_tripdata',
          table_name => 'green',
          mode => 'ADD'
        );
        CALL lakehouse.system.sync_partition_metadata(
          schema_name => 'nyc_tripdata',
          table_name => 'fhv',
          mode => 'ADD'
        );
      SQL

    05-nyc-tripdata-trino-validate: |
      trino --server ${TRINO_SERVER_URL} --insecure <<SQL
        SHOW SCHEMAS FROM lakehouse;
      
        SHOW TABLES FROM lakehouse.nyc_tripdata;
      
        DESCRIBE lakehouse.nyc_tripdata.yellow;
        DESCRIBE lakehouse.nyc_tripdata.green;
        DESCRIBE lakehouse.nyc_tripdata.fhv;
      
        SELECT *
        FROM lakehouse.nyc_tripdata.yellow
        LIMIT 10;
      SQL

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}
podLabels: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# Additional volumes on the output Deployment definition.
volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false

# Additional volumeMounts on the output Deployment definition.
volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true

nodeSelector: {}

tolerations: []

affinity: {}
